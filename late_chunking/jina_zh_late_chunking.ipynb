{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735b9f1d-aa29-4a6b-a0d7-bb1e4a56bdd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:27:19.547275Z",
     "iopub.status.busy": "2024-12-20T09:27:19.546732Z",
     "iopub.status.idle": "2024-12-20T09:27:26.642849Z",
     "shell.execute_reply": "2024-12-20T09:27:26.642158Z",
     "shell.execute_reply.started": "2024-12-20T09:27:19.547243Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/admin/anaconda3/envs/myenv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained('jinaai/jina-embeddings-v2-base-zh', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4841a955-1d88-4b39-be72-7a9183007bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:27:28.688076Z",
     "iopub.status.busy": "2024-12-20T09:27:28.686259Z",
     "iopub.status.idle": "2024-12-20T09:27:28.697457Z",
     "shell.execute_reply": "2024-12-20T09:27:28.696836Z",
     "shell.execute_reply.started": "2024-12-20T09:27:28.688028Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk_by_sentences(input_text: str, tokenizer: callable):\n",
    "    \"\"\"\n",
    "    Split the input text into sentences using the tokenizer\n",
    "    :param input_text: The text snippet to split into sentences\n",
    "    :param tokenizer: The tokenizer to use\n",
    "    :return: A tuple containing the list of text chunks and their corresponding token spans\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt', return_offsets_mapping=True)\n",
    "    punctuation_mark_id = tokenizer.convert_tokens_to_ids('。')\n",
    "    sep_id = tokenizer.eos_token_id\n",
    "    token_offsets = inputs['offset_mapping'][0]\n",
    "    token_ids = inputs['input_ids'][0]\n",
    "    chunk_positions = [\n",
    "        (i, int(start + 1))\n",
    "        for i, (token_id, (start, end)) in enumerate(zip(token_ids, token_offsets))\n",
    "        if token_id == punctuation_mark_id\n",
    "        and (\n",
    "            token_offsets[i + 1][0] - token_offsets[i][1] >= 0\n",
    "            or token_ids[i + 1] == sep_id\n",
    "        )\n",
    "    ]\n",
    "    chunks = [\n",
    "        input_text[x[1] : y[1]]\n",
    "        for x, y in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    span_annotations = [\n",
    "        (x[0], y[0]) for (x, y) in zip([(1, 0)] + chunk_positions[:-1], chunk_positions)\n",
    "    ]\n",
    "    return chunks, span_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d4d597-86ce-4419-bb97-c34263ca7241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:27:29.941603Z",
     "iopub.status.busy": "2024-12-20T09:27:29.941152Z",
     "iopub.status.idle": "2024-12-20T09:27:29.966738Z",
     "shell.execute_reply": "2024-12-20T09:27:29.966260Z",
     "shell.execute_reply.started": "2024-12-20T09:27:29.941575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks:\n",
      "- \"王安石（1021年12月19日－1086年5月21日），字介甫，号半山。\"\n",
      "- \"抚州临川县（今属江西省抚州市）人。\"\n",
      "- \"中国北宋时期政治家、文学家、思想家、改革家。\"\n",
      "- \"庆历二年（1042年），王安石中进士，历任扬州签判、鄞县知县、舒州通判等职，政绩显著。\"\n",
      "- \"宋仁宗末年，曾作《上仁宗皇帝言事书》，要求对宋初以来的法度进行全盘改革，但未被采纳。\"\n"
     ]
    }
   ],
   "source": [
    "input_text = \"王安石（1021年12月19日－1086年5月21日），字介甫，号半山。抚州临川县（今属江西省抚州市）人。中国北宋时期政治家、文学家、思想家、改革家。庆历二年（1042年），王安石中进士，历任扬州签判、鄞县知县、舒州通判等职，政绩显著。宋仁宗末年，曾作《上仁宗皇帝言事书》，要求对宋初以来的法度进行全盘改革，但未被采纳。\"\n",
    "\n",
    "# determine chunks\n",
    "chunks, span_annotations = chunk_by_sentences(input_text, tokenizer)\n",
    "print('Chunks:\\n- \"' + '\"\\n- \"'.join(chunks) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e069617-368c-4b58-8717-bb371841ae23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:30:46.441030Z",
     "iopub.status.busy": "2024-12-20T09:30:46.440427Z",
     "iopub.status.idle": "2024-12-20T09:30:46.451217Z",
     "shell.execute_reply": "2024-12-20T09:30:46.450339Z",
     "shell.execute_reply.started": "2024-12-20T09:30:46.440997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "14\n",
      "14\n",
      "34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "for chunk in chunks:\n",
    "    chunk_inputs = tokenizer(chunk, return_tensors='pt')\n",
    "    length = chunk_inputs['input_ids'].shape[1]\n",
    "    print(length - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bab847-582a-4694-a560-995c13f2ba8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:27:31.052797Z",
     "iopub.status.busy": "2024-12-20T09:27:31.052231Z",
     "iopub.status.idle": "2024-12-20T09:27:31.062700Z",
     "shell.execute_reply": "2024-12-20T09:27:31.062065Z",
     "shell.execute_reply.started": "2024-12-20T09:27:31.052765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 22), (22, 36), (36, 50), (50, 84), (84, 118)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c65f230-ac2c-4c65-8e87-ea99f89951fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:27:32.564695Z",
     "iopub.status.busy": "2024-12-20T09:27:32.564295Z",
     "iopub.status.idle": "2024-12-20T09:27:32.570489Z",
     "shell.execute_reply": "2024-12-20T09:27:32.569717Z",
     "shell.execute_reply.started": "2024-12-20T09:27:32.564674Z"
    }
   },
   "outputs": [],
   "source": [
    "def late_chunking(\n",
    "    model_output: 'BatchEncoding', span_annotation: list, max_length=None\n",
    "):\n",
    "    token_embeddings = model_output[0]\n",
    "    outputs = []\n",
    "    for embeddings, annotations in zip(token_embeddings, span_annotation):\n",
    "        if (\n",
    "            max_length is not None\n",
    "        ):  # remove annotations which go bejond the max-length of the model\n",
    "            annotations = [\n",
    "                (start, min(end, max_length - 1))\n",
    "                for (start, end) in annotations\n",
    "                if start < (max_length - 1)\n",
    "            ]\n",
    "        pooled_embeddings = [\n",
    "            embeddings[start:end].sum(dim=0) / (end - start)\n",
    "            for start, end in annotations\n",
    "            if (end - start) >= 1\n",
    "        ]\n",
    "        pooled_embeddings = [\n",
    "            embedding.detach().cpu().numpy() for embedding in pooled_embeddings\n",
    "        ]\n",
    "        outputs.append(pooled_embeddings)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffb465d-c525-4d88-9a34-9723a64655ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:27:34.903337Z",
     "iopub.status.busy": "2024-12-20T09:27:34.902946Z",
     "iopub.status.idle": "2024-12-20T09:27:35.105692Z",
     "shell.execute_reply": "2024-12-20T09:27:35.105332Z",
     "shell.execute_reply.started": "2024-12-20T09:27:34.903322Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# chunk before\n",
    "embeddings_traditional_chunking = model.encode(chunks)\n",
    "\n",
    "# chunk afterwards (context-sensitive chunked pooling)\n",
    "inputs = tokenizer(input_text, return_tensors='pt')\n",
    "model_output = model(**inputs)\n",
    "embeddings = late_chunking(model_output, [span_annotations])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2974f348-deb7-4c28-9c14-940593f06745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T09:28:15.043015Z",
     "iopub.status.busy": "2024-12-20T09:28:15.042216Z",
     "iopub.status.idle": "2024-12-20T09:28:15.051071Z",
     "shell.execute_reply": "2024-12-20T09:28:15.050337Z",
     "shell.execute_reply.started": "2024-12-20T09:28:15.042965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a448ac6b-e15f-4303-a6d0-c6556f58ef15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-20T08:51:54.744209Z",
     "iopub.status.busy": "2024-12-20T08:51:54.743553Z",
     "iopub.status.idle": "2024-12-20T08:51:54.805936Z",
     "shell.execute_reply": "2024-12-20T08:51:54.805458Z",
     "shell.execute_reply.started": "2024-12-20T08:51:54.744172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity_new(\"王安石是哪个朝代的\", \"王安石（1021年12月19日－1086年5月21日），字介甫，号半山。\"): 0.6774667\n",
      "similarity_trad(\"王安石是哪个朝代的\", \"王安石（1021年12月19日－1086年5月21日），字介甫，号半山。\"): 0.7342801\n",
      "similarity_new(\"王安石是哪个朝代的\", \"抚州临川县（今属江西省抚州市）人。\"): 0.61272216\n",
      "similarity_trad(\"王安石是哪个朝代的\", \"抚州临川县（今属江西省抚州市）人。\"): 0.27474773\n",
      "similarity_new(\"王安石是哪个朝代的\", \"中国北宋时期政治家、文学家、思想家、改革家。\"): 0.63981277\n",
      "similarity_trad(\"王安石是哪个朝代的\", \"中国北宋时期政治家、文学家、思想家、改革家。\"): 0.49549717\n",
      "similarity_new(\"王安石是哪个朝代的\", \"庆历二年（1042年），王安石中进士，历任扬州签判、鄞县知县、舒州通判等职，政绩显著。\"): 0.61709845\n",
      "similarity_trad(\"王安石是哪个朝代的\", \"庆历二年（1042年），王安石中进士，历任扬州签判、鄞县知县、舒州通判等职，政绩显著。\"): 0.57014936\n",
      "similarity_new(\"王安石是哪个朝代的\", \"宋仁宗末年，曾作《上仁宗皇帝言事书》，要求对宋初以来的法度进行全盘改革，但未被采纳。\"): 0.5486519\n",
      "similarity_trad(\"王安石是哪个朝代的\", \"宋仁宗末年，曾作《上仁宗皇帝言事书》，要求对宋初以来的法度进行全盘改革，但未被采纳。\"): 0.36279958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cos_sim = lambda x, y: np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
    "\n",
    "query = \"王安石是哪个朝代的\"\n",
    "# query = \"王安石是哪里人\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "for chunk, new_embedding, trad_embeddings in zip(chunks, embeddings, embeddings_traditional_chunking):\n",
    "    print(f'similarity_new(\"{query}\", \"{chunk}\"):', cos_sim(query_embedding, new_embedding))\n",
    "    print(f'similarity_trad(\"{query}\", \"{chunk}\"):', cos_sim(query_embedding, trad_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca89072-045f-4513-88d2-92a8de4a8bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893270b9-bab6-4007-a791-6b94682f9898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
